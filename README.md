# MongoDB Atlas GCP Terraform Module

Integrates MongoDB Atlas with Google Cloud Platform:

- **Encryption at Rest** using Google Cloud KMS (customer-managed keys)
- **PrivateLink** via Private Service Connect (PSC) with port-mapped architecture
- **Backup Export** to Google Cloud Storage (GCS)

## Public Preview Note

The MongoDB Atlas GCP Module (Public Preview) simplifies Atlas-GCP integrations and applies MongoDB's best practices as intelligent defaults. This preview validates that these patterns meet the needs of most workloads with minimal maintenance or rework. We welcome your feedback and contributions during this preview phase. MongoDB formally supports this module from its v1 release onwards.

## Disclaimer

One of the project's primary objectives is to provide durable modules that support non-breaking migration and upgrade paths. The v0 release (Public Preview) of the MongoDB Atlas GCP Module focuses on gathering feedback and refining the design. Upgrades from v0 to v1 may not be seamless. We plan to deliver a finalized v1 release with long-term upgrade support.

<!-- BEGIN_TOC -->
<!-- @generated
WARNING: This section is auto-generated. Do not edit directly.
Changes will be overwritten when documentation is regenerated.
Run 'just gen-readme' to regenerate. -->
- [Public Preview Note](#public-preview-note)
- [Disclaimer](#disclaimer)
- [Getting Started](#getting-started)
- [Examples](#examples)
- [Requirements](#requirements)
- [Providers](#providers)
- [Resources](#resources)
- [Required Variables](#required-variables)
- [GCP Cloud Provider Access](#gcp-cloud-provider-access)
- [Encryption at Rest](#encryption-at-rest)
- [Private Service Connect](#private-service-connect)
- [Backup Export](#backup-export)
- [Regions Mapping](#regions-mapping)
- [Optional Variables](#optional-variables)
- [Outputs](#outputs)
- [FAQ](#faq)
- [License](#license)
<!-- END_TOC -->

## Getting Started

This section guides you step-by-step on setting GCP up encryption at rest in MongoDB Atlas with Terraform.

<!-- BEGIN_GETTING_STARTED -->
<!-- @generated
WARNING: This section is auto-generated. Do not edit directly.
Changes will be overwritten when documentation is regenerated.
Run 'just gen-readme' to regenerate. -->
### Prerequisites

If you are familiar with Terraform and already have a project configured in MongoDB Atlas, go to [commands](#commands).

To deploy MongoDB Atlas in GCP with Terraform, ensure you meet the following requirements:

1. Install [Terraform](https://developer.hashicorp.com/terraform/install) to be able to run `terraform` [commands](#commands).
2. [Sign in](https://account.mongodb.com/account/login) or [create](https://account.mongodb.com/account/register) your MongoDB Atlas Account.
3. Configure your [Atlas authentication](https://registry.terraform.io/providers/mongodb/mongodbatlas/latest/docs#authentication) method.

   **NOTE**: Service Accounts (SA) are the preferred authentication method. See [Grant Programmatic Access to an Organization](https://www.mongodb.com/docs/atlas/configure-api-access/#grant-programmatic-access-to-an-organization) in the MongoDB Atlas documentation for detailed instructions on configuring SA access to your project.

4. Install and configure the [Google Cloud CLI](https://cloud.google.com/sdk/docs/install).

   ```sh
   gcloud init
   ```

   Authenticate in Google Cloud using one of the [supported methods](https://registry.terraform.io/providers/hashicorp/google/latest/docs/guides/provider_reference#authentication).

   The following example uses [Application Default Credentials](https://docs.cloud.google.com/docs/authentication/application-default-credentials):

    ```sh
    gcloud auth application-default login
    ```

5. Use an existing [MongoDB Atlas project](https://registry.terraform.io/providers/mongodb/mongodbatlas/latest/docs/resources/project) or [create a new Atlas project resource](#optional-create-a-new-atlas-project-resource).

### Commands

The following `terraform` commands intiate, apply, and destroy your configuration:

```sh
terraform init # this will download the required providers and create a `terraform.lock.hcl` file.
# configure authentication env-vars (MONGODB_ATLAS_XXX, GOOGLE_APPLICATION_CREDENTIALS)
# configure your `vars.tfvars` with required variables
terraform apply -var-file vars.tfvars
# cleanup
terraform destroy -var-file vars.tfvars
```

### (Optional) Create a New Atlas Project Resource

Add the following code to the `main.tf` file to set your configuration in a new Atlas project:

```hcl
variable "org_id" {
  type    = string
  default = "{ORG_ID}" # REPLACE with your organization id, for example `65def6ce0f722a1507105aa5`.
}

resource "mongodbatlas_project" "this" {
  name   = "cluster-module"
  org_id = var.org_id
}
```

Replace the `var.project_id` with `mongodbatlas_project.this.id` in the [main.tf](https://github.com/EspenAlbert/terraform-mongodbatlas-atlas-gcp/blob/v0.0.1/main.tf) file.

<!-- END_GETTING_STARTED -->

### Set Up a Complete GCP Configuration (Encryption, Backup Export, and PrivateLink)

Complete the following steps to configure encryption at rest, backup export, and PrivateLink with GCP using this module:

1. Prepare your terraform files.
  
   You can copy the files directly from the examples provided in this module:

    - [examples/complete/main.tf](https://github.com/EspenAlbert/terraform-mongodbatlas-atlas-gcp/blob/v0.0.1/examples/complete/main.tf)
    - [examples/complete/variables.tf](https://github.com/EspenAlbert/terraform-mongodbatlas-atlas-gcp/blob/v0.0.1/examples/complete/variables.tf)
    - [examples/complete/versions.tf](https://github.com/EspenAlbert/terraform-mongodbatlas-atlas-gcp/blob/v0.0.1/examples/complete/versions.tf)

   The following code example shows a basic example of a `main.tf` file configuration:

    ```hcl
    module "atlas_gcp" {
      source     = "terraform-mongodbatlas-modules/atlas-gcp/mongodbatlas"
      project_id = var.project_id

      encryption = {
        enabled = true
        create_kms_key = {
          enabled       = true
          key_ring_name = var.key_ring_name
          location      = var.gcp_region
        }
      }

      backup_export = {
        enabled = true
        create_bucket = {
          enabled       = true
          name_suffix   = var.bucket_name_suffix
          location      = var.gcp_region
          force_destroy = var.force_destroy
        }
      }

      privatelink_endpoints = var.privatelink_endpoints

      gcp_tags = var.gcp_tags
    }

    output "encryption" {
      value = module.atlas_gcp.encryption
    }

    output "encryption_at_rest_provider" {
      value = module.atlas_gcp.encryption_at_rest_provider
    }

    output "backup_export" {
      value = module.atlas_gcp.backup_export
    }

    output "export_bucket_id" {
      value = module.atlas_gcp.export_bucket_id
    }

    output "privatelink" {
      value = module.atlas_gcp.privatelink
    }

    output "resource_ids" {
      description = "All resource IDs created by the module"
      value       = module.atlas_gcp.resource_ids
    }
    ```

2. Prepare your [variables](#required-variables).

    The following example shows a `vars.tfvars` with the variables to provide at `apply` time:

    ```hcl
    project_id         = "YOUR_ATLAS_PROJECT_ID"
    gcp_project_id     = "YOUR_GCP_PROJECT_ID"
    gcp_region         = "YOUR_GCP_REGION"
    key_ring_name      = "atlas-encryption-keyring"
    bucket_name_suffix = "-dev"
    force_destroy      = false

    privatelink_endpoints = [
      {
        region     = "US_EAST_4"
        subnetwork = "projects/YOUR_GCP_PROJECT_ID/regions/YOUR_GCP_REGION/subnetworks/YOUR_SUBNETWORK_NAME"
        labels     = {}
      }
    ]
    ```

3. Provide your MongoDB Atlas credentials:

    ```sh
    export MONGODB_ATLAS_CLIENT_ID="your-client-id-goes-here"
    export MONGODB_ATLAS_CLIENT_SECRET="your-client-secret-goes-here"
    ```

    For more details on authentication methods, see [Prerequisites](#prerequisites).

4. Initialize and apply your Terraform configuration (See [Commands](#commands)).

5. Verify your [outputs](#outputs).

You now have encryption at rest, backup export, and PrivateLink configured with GCP.

See the [Examples](#examples) section for additional configurations.

### Clean up your configuration

Run `terraform destroy -var-file vars.tfvars` to undo all changes that Terraform made to your infrastructure.

<!-- BEGIN_TABLES -->
<!-- @generated
WARNING: This section is auto-generated. Do not edit directly.
Changes will be overwritten when documentation is regenerated.
Run 'just gen-readme' to regenerate. -->
## Examples

Feature | Name | Description
--- | --- | ---
All Features | [Encryption + Backup Export + PrivateLink](https://github.com/EspenAlbert/terraform-mongodbatlas-atlas-gcp/blob/v0.0.1/examples/complete) | Full integration using module-managed KMS key, GCS bucket, and PSC connectivity
Encryption at Rest | [GCP Cloud KMS Integration (User-Provided)](https://github.com/EspenAlbert/terraform-mongodbatlas-atlas-gcp/blob/v0.0.1/examples/encryption) | Encrypt Atlas data at rest using an existing Google Cloud KMS key version
Backup Export | [GCS Bucket Export (Module-Managed)](https://github.com/EspenAlbert/terraform-mongodbatlas-atlas-gcp/blob/v0.0.1/examples/backup_export) | Export Atlas backup snapshots to a module-managed GCS bucket
PrivateLink (PSC) | [Multi-Region Private Service Connect](https://github.com/EspenAlbert/terraform-mongodbatlas-atlas-gcp/blob/v0.0.1/examples/privatelink_multi_region) | Private connectivity across multiple GCP regions with auto-enabled regional mode
PrivateLink (PSC) | [BYOE (Bring Your Own Endpoint)](https://github.com/EspenAlbert/terraform-mongodbatlas-atlas-gcp/blob/v0.0.1/examples/privatelink_byoe) | Two-phase workflow for externally managed GCP forwarding rules

<!-- END_TABLES -->
<!-- BEGIN_TF_DOCS -->
<!-- @generated
WARNING: This section is auto-generated by terraform-docs. Do not edit directly.
Changes will be overwritten when documentation is regenerated.
Run 'just docs' to regenerate.
-->
## Requirements

The following requirements are needed by this module:

- <a name="requirement_terraform"></a> [terraform](https://developer.hashicorp.com/terraform/install) (>= 1.9)

- <a name="requirement_google"></a> [google](https://registry.terraform.io/providers/hashicorp/google/latest/docs) (>= 6.0)

- <a name="requirement_mongodbatlas"></a> [mongodbatlas](https://registry.terraform.io/providers/mongodb/mongodbatlas/latest/docs) (~> 2.7)

## Providers

The following providers are used by this module:

- <a name="provider_mongodbatlas"></a> [mongodbatlas](https://registry.terraform.io/providers/mongodb/mongodbatlas/latest/docs) (~> 2.7)

- <a name="provider_terraform"></a> [terraform](https://developer.hashicorp.com/terraform/language/resources/terraform-data)

## Resources

The following resources are used by this module:

- [mongodbatlas_private_endpoint_regional_mode.this](https://registry.terraform.io/providers/mongodb/mongodbatlas/latest/docs/resources/private_endpoint_regional_mode) (resource)
- [mongodbatlas_privatelink_endpoint.this](https://registry.terraform.io/providers/mongodb/mongodbatlas/latest/docs/resources/privatelink_endpoint) (resource)
- [terraform_data.region_validations](https://developer.hashicorp.com/terraform/language/resources/terraform-data) (resource)

<!-- BEGIN_TF_INPUTS_RAW -->
<!-- @generated
WARNING: This grouped inputs section is auto-generated. Do not edit directly.
Changes will be overwritten when documentation is regenerated.
Run 'just docs' to regenerate.
-->
## Required Variables

### project_id

MongoDB Atlas project ID

Type: `string`


## GCP Cloud Provider Access

Atlas requires a GCP service account to access your Google Cloud resources (KMS keys for encryption, GCS buckets for backup export). Unlike AWS and Azure, Atlas creates and manages this service account automatically -- you only need to grant it IAM roles on your resources.

The module creates a shared Cloud Provider Access (CPA) setup by default when encryption or backup export is enabled. You can also reuse an existing CPA by setting `create = false` with `existing.role_id` and `existing.service_account_for_atlas`. PrivateLink-only configurations skip CPA entirely since PSC uses GCP resources only.

See the [GCP cloud provider access documentation](https://www.mongodb.com/docs/atlas/security/set-up-gcp-access/) for details.

### cloud_provider_access

Cloud provider access configuration for Atlas-GCP integration.
- `create = true` (default): Creates a shared Atlas service account and authorization
- `create = false`: Use existing CPA via `existing.role_id` and `existing.service_account_for_atlas`

Type:

```hcl
object({
  create = optional(bool, true)
  existing = optional(object({
    role_id                   = string
    service_account_for_atlas = string
  }))
})
```

Default: `{}`


## Encryption at Rest

Atlas encrypts data at rest by default with Atlas-managed keys. Enable customer-managed encryption when compliance or regulatory requirements mandate that you control the encryption keys. Customer-managed encryption gives you full lifecycle control over key rotation, access policies, and key destruction.

Provide either a user-managed KMS key (`key_version_resource_id`) or let the module create one (`create_kms_key.enabled = true`). The module grants the Atlas service account the necessary IAM roles (`roles/cloudkms.cryptoKeyEncrypterDecrypter`, `roles/cloudkms.viewer`) on the key.

See the [GCP encryption documentation](https://www.mongodb.com/docs/atlas/security-gcp-kms/) for details.

### encryption

Encryption at rest configuration with Google Cloud KMS.

Provide EITHER:
- `key_version_resource_id` (user-provided KMS key version)
- `create_kms_key.enabled = true` (module-managed Key Ring + Crypto Key)

`key_ring_name` sets the name for the GCP KMS key ring. When omitted, defaults to
`atlas-{project_id}-keyring` to avoid collisions across Atlas projects sharing the
same GCP project and location. Key rings are permanent in GCP -- choose stable names.
GCP allows 1-63 characters (`[a-zA-Z][a-zA-Z0-9_-]*`); the auto-generated name is
38 characters (well within the limit).

`crypto_key_name` sets the name for the GCP KMS crypto key within the key ring.
When omitted, defaults to `atlas-encryption-key`. No project ID prefix needed since
the key is already scoped within the key ring.

`location` accepts GCP locations (`us-east4`) or Atlas region names (`US_EAST_4`).
Multi-regional locations (`us`, `europe`, `asia`) are also valid.

`rotation_period` controls GCP automatic key version rotation.
Format: seconds as string, e.g., "7776000s" (90 days). Should be > 86400s (1 day).
When omitted, no automatic rotation occurs. Atlas recommends 90-day rotation and
creates an alert at that cadence. Each rotation causes a plan diff on
key_version_resource_id on the next terraform apply. Old key versions remain
enabled -- no data re-encryption is needed.

`enabled_for_search_nodes` (default: `true`) opts the project into BYOK encryption for
dedicated search nodes. The flag alone is not sufficient -- Atlas also requires cluster-level
BYOK and an internal feature flag. In projects without search nodes, this is a no-op.
On existing deployments with search nodes, flipping false->true triggers search node
reprovisioning and index rebuild (search may be temporarily unavailable).

`dedicated_role_enabled = true` creates a dedicated Atlas service account for encryption.

Type:

```hcl
object({
  enabled                 = optional(bool, false)
  key_version_resource_id = optional(string)
  create_kms_key = optional(object({
    enabled         = optional(bool, false)
    key_ring_name   = optional(string)
    crypto_key_name = optional(string)
    location        = optional(string, "")
    rotation_period = optional(string)
  }), {})
  enabled_for_search_nodes = optional(bool, true)
  dedicated_role_enabled   = optional(bool, false)
})
```

Default: `{}`


## Private Service Connect

Private Service Connect (PSC) enables private connectivity between your GCP VPCs and MongoDB Atlas, keeping traffic off the public internet. Use PSC when your security policy requires private-only network access to Atlas clusters.

The module supports two connectivity paths (mutually exclusive):
- **Module-managed:** Provide a subnetwork per region via `privatelink_endpoints` or `privatelink_endpoints_single_region`. The module creates the GCP forwarding rules and compute addresses.
- **Bring Your Own Endpoint (BYOE):** Use the BYOE path if you have multiple teams that manage GCP networking separately. This is a 2-phase workflow:
  1. Declare regions via `privatelink_byoe_regions` -- the module creates the Atlas endpoint service and outputs `service_attachment_names`
  2. Create your own forwarding rules externally, then pass the details via `privatelink_byoe`

See the [Atlas private endpoints documentation](https://www.mongodb.com/docs/atlas/security-private-endpoint/) for details.

### privatelink_endpoints

Create multi-region PrivateLink endpoints via Private Service Connect (PSC).

Each entry creates one GCP forwarding rule and address pair per region. PSC uses
port-mapped architecture where one forwarding rule handles routing to all MongoDB
nodes internally.

Mutually exclusive with `privatelink_endpoints_single_region`.

- `region` accepts both GCP format (`us-east4`) and Atlas format (`US_EAST_4`).
  All regions must be unique -- use `privatelink_endpoints_single_region` for
  multiple VPCs in the same region.
- `subnetwork` is a self_link (e.g., `google_compute_subnetwork.this.self_link`).
  The VPC network is derived from the subnetwork -- no separate `network` input is needed.
- `labels` are applied to the GCP forwarding rule and compute address resources.
- `name_prefix` sets the prefix for the GCP compute address (`{name_prefix}ip`) and
  forwarding rule (`{name_prefix}fr`). When omitted, defaults to `atlas-psc-{region}-`
  where region is in GCP format (e.g., `atlas-psc-us-east4-`). Set a custom prefix when
  multiple deployments share the same GCP project and region to avoid name collisions.

Type:

```hcl
list(object({
  region      = string
  subnetwork  = string
  labels      = optional(map(string), {})
  name_prefix = optional(string)
}))
```

Default: `[]`

### privatelink_endpoints_single_region

Create single-region PrivateLink endpoints for multiple VPCs in the same GCP region.

Use this variable when two or more VPCs in the same region each need PSC
connectivity to the same Atlas project. It uses the list index as the `for_each`
key (not the region), since the region is identical for all entries.

Mutually exclusive with `privatelink_endpoints`.

- `name_prefix` sets the prefix for the GCP compute address (`{name_prefix}ip`) and
  forwarding rule (`{name_prefix}fr`). When omitted, defaults to `atlas-psc-{index}-`
  where index is the list position (e.g., `atlas-psc-0-`). Recommended to set explicitly
  since index-based defaults are not descriptive.

Type:

```hcl
list(object({
  region      = string
  subnetwork  = string
  labels      = optional(map(string), {})
  name_prefix = optional(string)
}))
```

Default: `[]`

### privatelink_byoe_regions

BYOE (Bring Your Own Endpoint) Phase 1: declare regions for Atlas endpoint service creation.

Each key is a user-chosen identifier (not necessarily a region name). Each value
is a GCP region (`us-east4` or `US_EAST_4`). Atlas creates the endpoint service
and returns `service_attachment_names` via the `privatelink_service_info` output.

Regions must not overlap with `privatelink_endpoints` regions.
Phase 2 (`privatelink_byoe`) completes the connection.

Type: `map(string)`

Default: `{}`

### privatelink_byoe

BYOE (Bring Your Own Endpoint) Phase 2: complete the PSC connection.

After Phase 1 returns `service_attachment_names`, create your own
`google_compute_address` + `google_compute_forwarding_rule` targeting
`service_attachment_names[0]`, then pass the details here.

- `ip_address` is the internal IP of your `google_compute_address`.
- `forwarding_rule_name` is the GCP resource name of your `google_compute_forwarding_rule`.
- `gcp_project_id` is used when the forwarding rule lives in a different GCP project than the provider default.
- Key must exist in `privatelink_byoe_regions`.

Both phases can run in a single `terraform apply` (see the `privatelink_byoe` example).

Type:

```hcl
map(object({
  ip_address           = string
  forwarding_rule_name = string
  gcp_project_id       = optional(string)
}))
```

Default: `{}`


## Backup Export

Atlas Cloud Backup takes automatic snapshots of your clusters. Enable backup export to copy these snapshots to a Google Cloud Storage (GCS) bucket you control, providing an independent recovery path outside of Atlas and meeting data residency or retention requirements.

Provide either an existing bucket (`bucket_name`) or let the module create one with secure defaults (`create_bucket.enabled = true`).

### backup_export

Backup snapshot export to GCS configuration.

Provide EITHER:
- `bucket_name` (user-provided GCS bucket)
- `create_bucket.enabled = true` (module-managed GCS bucket)

**Bucket Naming:**
- `name` accepts a string to set an explicit bucket name (must be globally unique in GCS). When omitted, the bucket name is auto-generated as `atlas-backup-{project_id}`.
- `name_suffix` accepts a string appended to the auto-generated name, resulting in `atlas-backup-{project_id}{name_suffix}`. Include a separator (e.g. `"-dev"` produces `atlas-backup-{project_id}-dev`). Mutually exclusive with `name`.

**Location:**
`location` accepts GCP regions (`us-east4`), Atlas format (`US_EAST_4`),
multi-regions (`US`, `EU`, `ASIA`), or dual-regions (`NAM4`, `EUR4`).
Atlas format is normalized via `atlas_to_gcp_region`. Choose a region
colocated with the Atlas cluster for lowest latency.

**Security:**
- `uniform_bucket_level_access` accepts `true` or `false` to control IAM-only access (no per-object ACLs). Defaults to `true`.
- `public_access_prevention` accepts `"enforced"` to block public access or `"inherited"` to use project-level settings. Defaults to `"enforced"`.
- `versioning_enabled` accepts `true` or `false` to enable or disable object versioning for backup recovery. Defaults to `true`.

`dedicated_role_enabled = true` creates a dedicated Atlas service account for backup export.

Type:

```hcl
object({
  enabled     = optional(bool, false)
  bucket_name = optional(string)
  create_bucket = optional(object({
    enabled                     = optional(bool, false)
    name                        = optional(string, "")
    name_suffix                 = optional(string, "")
    location                    = optional(string, "")
    force_destroy               = optional(bool, false)
    storage_class               = optional(string, "STANDARD")
    versioning_enabled          = optional(bool, true)
    uniform_bucket_level_access = optional(bool, true)
    public_access_prevention    = optional(string, "enforced")
  }), {})
  dedicated_role_enabled = optional(bool, false)
})
```

Default: `{}`


## Regions Mapping

Internal mapping between Atlas region names (`US_EAST_4`) and GCP region names (`us-east4`). The module uses this mapping to normalize all region inputs -- you can use either format in any region variable. Override this variable to restrict allowed regions or add custom mappings.

### atlas_to_gcp_region

Atlas to GCP region mapping. Keys = Atlas format, values = GCP format.
The module accepts either format in all region inputs and normalizes internally.
Override to restrict allowed regions or add custom mappings.

Type: `map(string)`

Default:

```json
{
  "AFRICA_SOUTH_1": "africa-south1",
  "ASIA_EAST_2": "asia-east2",
  "ASIA_NORTHEAST_2": "asia-northeast2",
  "ASIA_NORTHEAST_3": "asia-northeast3",
  "ASIA_SOUTHEAST_2": "asia-southeast2",
  "ASIA_SOUTH_1": "asia-south1",
  "ASIA_SOUTH_2": "asia-south2",
  "AUSTRALIA_SOUTHEAST_1": "australia-southeast1",
  "AUSTRALIA_SOUTHEAST_2": "australia-southeast2",
  "CENTRAL_US": "us-central1",
  "EASTERN_ASIA_PACIFIC": "asia-east1",
  "EASTERN_US": "us-east1",
  "EUROPE_CENTRAL_2": "europe-central2",
  "EUROPE_NORTH_1": "europe-north1",
  "EUROPE_SOUTHWEST_1": "europe-southwest1",
  "EUROPE_WEST_10": "europe-west10",
  "EUROPE_WEST_12": "europe-west12",
  "EUROPE_WEST_2": "europe-west2",
  "EUROPE_WEST_3": "europe-west3",
  "EUROPE_WEST_4": "europe-west4",
  "EUROPE_WEST_6": "europe-west6",
  "EUROPE_WEST_8": "europe-west8",
  "EUROPE_WEST_9": "europe-west9",
  "MIDDLE_EAST_CENTRAL_1": "me-central1",
  "MIDDLE_EAST_CENTRAL_2": "me-central2",
  "MIDDLE_EAST_WEST_1": "me-west1",
  "NORTHEASTERN_ASIA_PACIFIC": "asia-northeast1",
  "NORTH_AMERICA_NORTHEAST_1": "northamerica-northeast1",
  "NORTH_AMERICA_NORTHEAST_2": "northamerica-northeast2",
  "NORTH_AMERICA_SOUTH_1": "northamerica-south1",
  "SOUTHEASTERN_ASIA_PACIFIC": "asia-southeast1",
  "SOUTH_AMERICA_EAST_1": "southamerica-east1",
  "SOUTH_AMERICA_WEST_1": "southamerica-west1",
  "US_EAST_4": "us-east4",
  "US_EAST_5": "us-east5",
  "US_SOUTH_1": "us-south1",
  "US_WEST_2": "us-west2",
  "US_WEST_3": "us-west3",
  "US_WEST_4": "us-west4",
  "WESTERN_EUROPE": "europe-west1",
  "WESTERN_US": "us-west1"
}
```


## Optional Variables

Additional configuration options that apply across all features.

### gcp_tags

Labels to apply to all GCP resources created by this module.

Type: `map(string)`

Default: `{}`

<!-- END_TF_INPUTS_RAW -->

The module exports outputs grouped by feature. Use `encryption_at_rest_provider` and `export_bucket_id` when configuring your Atlas cluster resource. Use `privatelink_service_info` for the BYOE workflow. Connection strings come from the cluster resource, not this module.

## Outputs

The following outputs are exported:

### <a name="output_backup_export"></a> [backup\_export](#output\_backup\_export)

Description: Backup export configuration and GCS bucket details

### <a name="output_encryption"></a> [encryption](#output\_encryption)

Description: Encryption at rest status and KMS configuration

### <a name="output_encryption_at_rest_provider"></a> [encryption\_at\_rest\_provider](#output\_encryption\_at\_rest\_provider)

Description: Value for cluster's encryption\_at\_rest\_provider attribute

### <a name="output_export_bucket_id"></a> [export\_bucket\_id](#output\_export\_bucket\_id)

Description: Export bucket ID for backup schedule auto\_export\_enabled

### <a name="output_privatelink"></a> [privatelink](#output\_privatelink)

Description: PrivateLink status per endpoint key (both module-managed and BYOE)

### <a name="output_privatelink_service_info"></a> [privatelink\_service\_info](#output\_privatelink\_service\_info)

Description: Atlas PrivateLink service info per endpoint key (for BYOE - create your GCP PSC endpoint using these values)

### <a name="output_regional_mode_enabled"></a> [regional\_mode\_enabled](#output\_regional\_mode\_enabled)

Description: Whether private endpoint regional mode is enabled (auto-enabled for multi-region)

### <a name="output_resource_ids"></a> [resource\_ids](#output\_resource\_ids)

Description: GCP resource IDs for data source lookups

### <a name="output_role_id"></a> [role\_id](#output\_role\_id)

Description: Atlas role ID for reuse with other Atlas-GCP features
<!-- END_TF_DOCS -->

## FAQ

**Why does the module require mongodbatlas provider ~> 2.7?**

Provider [v2.7.0](https://github.com/mongodb/terraform-provider-mongodbatlas/blob/master/CHANGELOG.md#270-february-18-2026) added `port_mapping_enabled` on `mongodbatlas_privatelink_endpoint`, required for port-mapped PSC architecture.

**How does region format work?**

All region variables accept both GCP format (`us-east4`) and Atlas format (`US_EAST_4`). The module normalizes internally using a static 41-entry mapping.

**Why is there no encryption private endpoint support?**

Atlas does not support private endpoints for GCP KMS. Only AWS KMS (via PrivateLink) and Azure Key Vault (via Private Link) are supported.

**What is the difference between `privatelink_endpoints` and `privatelink_endpoints_single_region`?**

`privatelink_endpoints` is for multi-region deployments (unique region per entry, region used as `for_each` key). `privatelink_endpoints_single_region` is for multiple VPCs in the same region (list index as key). They are mutually exclusive.

## License

See [LICENSE](https://github.com/EspenAlbert/terraform-mongodbatlas-atlas-gcp/blob/v0.0.1/LICENSE) for full details.
